---
title: "ESG Content Analysis on US companies"
author: "QTA group 2"
date: "5/19/2021"
output: html_document
---
## Table of Content (temporary)
**Introduction**

**Sample selection and data**

**Research question**

**Readability and the nature of 10K fillings**

**Correspondence**

**Collocation Analysis**

**Applied dictionaries**

**Relative ESG-wording**

**Comparison with ESG-Ratings**

**Trends between industries**

**Limitations**

```{r Loading packages and load/prepare 10Ks, include=FALSE}
# load packages
library(readtext)
library(dplyr)
library(here)
library(readxl)
library(quanteda)
library(stringr)
library(tidyverse)
library(ggplot2)
library(plotly)

# load excel files with cik numbers for each industry with the companies
fashion <- read_excel(here("companies", "fashion_cik.xlsx"), sheet = "Sheet1", col_names = TRUE)
# energy <- read_excel()
# industry3 <- read_excel()

# keeping only the cik number
fashion_cik <- fashion[,13]
# energy_cik <- energy[,13]
# industry3_cik <- industry3[,13]

# load the 10Ks from downloaded files

fashion_10k <- NULL
energy_10k <- NULL
industry3_10k <- NULL

# loop that collects all reports for all companies for each industry
# this will take some minutes!!!

# fashion (should be 436 observations)
for (i in fashion_cik$CIK) {
  output <- readtext(here("Edgar filings_HTML view", "Form 10-K", i))
  fashion_10k <- rbind(fashion_10k, output)
}

# energy
for (i in energy_cik$CIK) {
  output <- readtext(here("Edgar filings_HTML view", "Form 10-K", i))
  fashion_10k <- rbind(all, output)
}

# industry3
for (i in industry_cik$CIK) {
  output <- readtext(here("Edgar filings_HTML view", "Form 10-K", i))
  fashion_10k <- rbind(all, output)
}

# simple cleaning
fashion_10k$text <- str_remove_all(fashion_10k$text, "\nâ€¢")
fashion_10k$text <- str_remove_all(fashion_10k$text, "\n")
#energy_10k
#industry3

# define columns into cik, report type and report year
fashion_10k <- separate(
  fashion_10k,
  1,
  into = c("cik", "type", "year", NA),
  sep = "_",
  remove = TRUE)

#energy
#industry3

# only keep year
#keep the year and not the full date
fashion_10k <- separate(
  fashion_10k,
  "year",
  into = c("year", NA),
  sep = "-",
  remove = TRUE)

#energy
#industry3
```


**Introduction**

**Sample selection and data**
We took the 10K filings back to the year 2004. This leads to 18 reports if the on from 2021 was already made public.For the fashion industry we have a average of `r round(ndoc(fashion_10k)/length(unique(fashion_10k$cik)), digits = 2)` total 10K filings per company. This is due to some later SEC registrations after 2004 for some companies.

**Research question**

**Readability and the nature of 10K fillings**
```{r creating a corpus and apply the readability measures, include=FALSE}
# creating a corpus

fashion_corp <- corpus(fashion_10k)
#energy
#industry3


# apply Flesch readability measure (takes a few minutes)

fashion_rd_flesch <- fashion_corp %>%
  textstat_readability(measure = "Flesch", remove_hyphens = TRUE)
#energy
# industry3

# apply FOG readability measure (takes a few minutes)

fashion_rd_fog <- fashion_corp %>%
  textstat_readability(measure = "FOG", remove_hyphens = TRUE)
#energy
#industry3
```
Flesch

There are many different methods to try to measure the complexity of a underlying text source. Most measures take somehow into account the text structure, the length of sentences, the difficulty of used words and the usage of infrequent words. One of the first readability measures was developed by Rudolph Flesch back in 1948. As one of the oldest but still frequently used measure for readability it tries to reflect the complexity of a text by the average sentence length and the average number of syllables per word. The Flesch Reading Ease readability measure works with an index ranging from 0 to 100, with a higher index representing a simpler text to read. Theoretically a maximum score of 121.22 can be attended if every sentence just have a one-syllable word. There is also no lower limit. Therefore, some very complicated sentences can cause negative scores. With an average index of `r round(mean(fashion_rd_flesch$Flesch), digits = 2)` the 10Ks seem to be very complex based on the Flesch measure. A score below the score of 30 indicates a high difficulty to read the text and is best understood by university graduates. On the plot below the Flesch score for each company in our fashion sample across all years is shown. The readability scores tend to be more different between companies during the earlier years in our sample. From 2012 the companies have more similar reflected complexity as the scores vary much less as for the earlier ears. This can be due to more standardized restrictions by the SEC, but for the last two years 2020 and 2021 the scores do vary more again. Additionally, the complexity is increasing towards the present what is represented by a lower score. For the two last years multiple Flesch scores are below zero, suggesting these are very complicated texts to deal with. The higher variation and measured complexity could be caused by  COVID at how the firms are differently affected by the virus.

references:
- https://readabilityformulas.com/flesch-reading-ease-readability-formula.php
- Measuring Readability in Financial Disclosures; TIM LOUGHRAN and BILL MCDONALD; 2014

```{r Readability plots Flesch, echo = FALSE}

# all companies, all years
ggplotly(ggplot(fashion_rd_flesch, aes(x=fashion_10k$year, y =Flesch, colour=fashion_10k$cik)) + geom_point() +
           ggtitle("Flesch - Readability"), tooltip = c("colour", "y", "x"))
```


**Correspondence**

**Collocation Analysis**

**Applied dictionaries**

**Relative ESG-wording**

**Comparison with ESG-Ratings**

**Trends between industries**

**Limitations**
