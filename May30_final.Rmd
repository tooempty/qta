---
title: "ESG Content Analysis on US companies"
author: "QTA group 2"
date: "5/19/2021"
output:
  html_document: default
  pdf_document: default
---
## Table of Content (temporary)	
  Introduction // Research Question H1/H2 // Data collection and sample selection // Dictionary Evaluation // Comparison ESG wording with Rating // Comparison ESG wording/rating with size // Conclusion // Appendix

```{r Loading packages and load/prepare 10Ks for fashion, include=FALSE}
# load packages
library(readtext)
library(dplyr)
library(here)
library(readxl)
library(quanteda)
library(quanteda.textmodels)
library(stringr)
library(tidyverse)
library(ggplot2)
library(plotly)
library(quanteda.textstats)
library(quanteda.textplots)
library(kableExtra)
library(tis)
library(corrplot)
library(stargazer)
library(caret)
library(rpart) 
library(rpart.plot) 
library(ipred) 
library(vip)

# load excel files with cik numbers for each industry with the companies
fashion <- read_excel(here("fashion_cik.xlsx"), sheet = "Sheet1", col_names = TRUE)
fashion <- fashion[, c(1, 4:14)]

# keeping only the cik number
fashion_cik <- fashion$CIK

# load the 10Ks from downloaded files
fashion_10k <- NULL

# loop that collects all reports for all companies for each industry
# this will take some minutes!!!
# fashion (should be 436 observations)
for (i in fashion_cik) {
  output <- readtext(here("fashion_10k", i))
  fashion_10k <- rbind(fashion_10k, output)
}
rm(output)

# simple cleaning
fashion_10k$text <- str_remove_all(fashion_10k$text, "\n•")
fashion_10k$text <- str_remove_all(fashion_10k$text, "\n")

# define columns into cik, report type and report year
fashion_10k <- separate(
  fashion_10k,
  1,
  into = c("cik", "type", "year", NA),
  sep = "_",
  remove = TRUE)

# only keep year
# keep the year and not the full date
fashion_10k <- separate(
  fashion_10k,
  "year",
  into = c("year", NA),
  sep = "-",
  remove = TRUE)
```

```{r Correction wrong file name, include = FALSE}
wrong_year <- which(fashion_10k$year == "2016–0.html") # there is a mis-specification in splitting of 2016 
fashion_10k[wrong_year, 3] = 2016 # re-write the value in the cell as 2016 correctly
rm(wrong_year) #remove the unnecessary variable
```

#### Introduction and Research Questions ####		#### Introduction ####
Corporate Social Responsibility (CSR) is becoming increasingly important. As governments struggle to find solutions for environmental and social issues, corporations face an increasing pressure to not only be financially successful, but also to conduct their business in a sustainable and ethical way. Consumers and investors want to know how their products are produced and if the company adheres to certain standards. 		In recent years, social responsibility has become a standard measure for every company. Companies are not only measured by their financial success, but also how they conduct their business. ESG ratings are commonly used to compare their performance across industries and sectors.
Yet while the financial success of a company is easy to check and compare, the same is not true for CSR. 		But regardless of how well a company actually adheres to ESG standards, it will usually want present its actions in a favorable way.
ESG-Ratings are commonly used to compare performance across industries and sectors. But there is no standard for these rating and the methodology is not publicly available. Subsequently, the ESG-ratings can differ substantially for the same company (Berg, Kölbel and Rigobon, 2020).  

Baier, Berninger and Kiesel (2020) stated: "Financial reporting, or more precisely annual reports, are identified to be the most reliable disclosure to quantify a firm’s contribution to CSR." 		#### Sample selection and data ####
This is why we want to focus on the usage of ESG-wording in annual reports. An annual report usually differs from company to company in scope, detail and presentation. This makes it more difficult to compare one specific aspect of annual reporting, as we want with the ESG-wording. This is a major advantage of 10Ks reports, which is very often chosen as the data basis for various studies. Both the structure and the required information content are specified by the SEC for all companies enlisted in the US. With the greater standardization of financial presentation, there is the advantage of a more precise differentiation of the content.		At the beginning of our work, we wanted to take a closer look at two industries where ESG is quite a popular topic. We chose the fashion industry and energy companies in oil and gas sectors. Later, we added the beverage industry to compare our results with an industry with little to no perceived ESG importance. To identify industry corresponding companies with their country of exchange being the US we used the Refinitiv Workspace access from the University of St. Gallen. Also to receive a first ESG rating measure we refer to the data from Refinitiv. More precisely we used the screener application from the workspace to filter for the companies we wanted to examine. To identify the correct industry we chose to filter for the Global Industry Classification Standard (GICS). This lead us first to 74 fashion industries. We then excluded the companies where we do not have any ESG rating for the actual year. Our resulting sample of US fashion industries consists of 27 firms. Out of 476 energy companies restricting to only the oil, gas and consumable fuels sector the ESG rating was provided by Refinitiv for 108 companies. To compare it with our fashion sample we further took a random sample of 30 energy companies. For the beverage companies a total of 25 companies resulted.
We will look at what role the different ESG dimensions play across different industries and if a higher mention of ESG related words correlate with a higher rating. The following two hypotheses will be tested: 		
  		
 H1: A higher mention of ESG-wording in 10K reports leads to higher ESG-Ratings.		
As we suspect that bigger and more successful companies have more resources available to invest in ESG measures, we will further look at the size and financial performance and if that reflects in the ESG-Ratings.

 H2: Larger companies have more ESG-wording in 10K reports and therefore a higher ESG-Rating. 
 
We choose the Refinitiv ESG-Rating as our benchmark and will analyze 10K reports across three different industry sectors (energy, fashion and beverages) in the timespan of 2004-2021.  		
#### Sample selection and data ####		
To examine our research questions the choice was made to examine industries that are typically addressed with ESG-relating topics (fashion and energy industry). In order to distinguish the companies and trends an additional industry was added where there is less controversy and also less perceived importance about ESG issues. In order to work with 10-Ks as annual reporting standards the companies had to be enlisted on an US-exchange. With the screener application from Refintiv Workspace with HSG access only those companies were kept with at least one ESG-Rating provided. This resulted in a sample of 27 fashion firms and 108 gas and oil companies. For comparison reasons our energy sample was randomly reduced to 30 companies. From the beverage industry, 26 companies were identified as suitable.

By combination of manual search and the use of the getFilingsHTML function form the R package "edgar" the 10-K filings from these 82 companies have been collected back to the year 2004. It makes little sense to go beyond 2004 because there are only a small number of ESG-ratings for earlier years or a significant amount of companies were not even enlisted back then. However, if a company was already listed in 2004 we would get 18 reports in total if the one from the actual year 2021 was already made public. For the fashion industry there is an average of `r round(ndoc(fashion_10k)/length(unique(fashion_10k$cik)), digits = 2)` total 10-K filings per company. Regarding the energy companies an average of `r round(ndoc(energy_10k)/length(unique(fashion_10k$cik)), digits = 2)` 10-K reports can be found and for beverages it is an average of `r round(ndoc(energy_10k)/length(unique(bev_10k$cik)), digits = 2)` filings.

As mentioned the best alternative to get the 10-K filings was not really satisfying, a lot of double checks had to be made to ensure the correct underlying text source for each 10-K. In addition to this manual verification, a readability analysis proved to be a useful tool to ensure the correctness of the data. Additionally, it reflected a similar message when applying two of the most typical readability measures (Flesch and FOG). First, all 10-Ks are regarded as very complex and very hard understanding documents with barley no difference between companies or industry. Second there is a slight increase in complexity towards the newest years. (Appendix 1)		We will looking at the following two main questions.
To compare our analysis based on differences in ESG wording in the reports across industries, first the samples of the respective industries were searched for outliers to ensure a homogenic picture within an industry. A two-dimensional correspondence analysis was conducted to identify those companies with widely differing reports. Further, it supports the trend of higher variety in 10Ks in more recent years compared to current years as concluded by the readability measures. This could be an indication that a greater 10-K filings standardization by the SEC could have taken place towards the present. Is is to point out that the beverage companies make the largest differences between each other. Thus, providing a first indication of a more heterogenic sample regarding the beverage companies. (Appendix 2: Comparison Correspondence Analysis 2020 fashion vs. beverages)		Is there a correlation between the wording of a 10-K report and the ESG-score of a company?


```{r Creating a corpus and apply the readability measures for fashion, include=FALSE}
# creating a corpus
fashion_corp <- corpus(fashion_10k)
# apply Flesch readability measure (takes a few minutes)
fashion_rd_flesch <- fashion_corp %>%
  textstat_readability(measure = "Flesch", remove_hyphens = TRUE)
# apply FOG readability measure (takes a few minutes)
fashion_rd_fog <- fashion_corp %>%
  textstat_readability(measure = "FOG", remove_hyphens = TRUE)
```



```{r Readability plots Flesch for fashion, echo = FALSE, fig.width = 10 , fig.fullwidth=TRUE}
# all companies, all years
plot_flesch <- ggplotly(ggplot(fashion_rd_flesch, aes(x=fashion_10k$year, y =Flesch, colour=fashion_10k$cik)) + geom_point() +  ggtitle("Flesch - Readability for fashion companies"), tooltip = c("colour", "y", "x") )

x <- list(
    title = "year")

y <- list(
    title = "Readability score")

plot_flesch %>% layout(xaxis = x, yaxis = y)
```


```{r Readability plots FOG for fashion, echo = FALSE, fig.width = 10 , fig.fullwidth=TRUE}
# all companies, all years
plt_fog <- ggplotly(ggplot(fashion_rd_fog, aes(x=fashion_10k$year, y =FOG, color=fashion_10k$cik)) + coord_cartesian(ylim = c(15, 38)) + geom_point() + ggtitle("FOG - Readability for fashion companies"), tooltip = c("colour", "y", "x"))

plt_fog %>% layout(xaxis = x, yaxis = y)

rm(x, y)
```

####Correspondence ####

```{r Correspondance analysis 2004 and 2020, include = FALSE}
# analysis only on one year across companies to have only max 27 data points (otherwise way too much)
# filter out the years 2004 and 2020 to show difference in correspondance
fashion_2004 <- fashion_10k %>%
  filter(year == 2004)
fashion_2020 <- fashion_10k %>%
  filter(year == 2020)
## create corpus
fashion_04_corp <- corpus(fashion_2004)
fashion_20_corp <- corpus(fashion_2020)
## Tokenization
fashion_04_tokens <- fashion_04_corp %>%
  tokens(remove_punct = TRUE, # remove punctuation
         remove_numbers = TRUE, # remove numbers
         remove_symbols = TRUE) %>% # remove symbols
  tokens_tolower() # everything to lower cases
fashion_04_tokens <- fashion_04_tokens %>%
  tokens_remove(stopwords("english"))
fashion_20_tokens <- fashion_20_corp %>%
  tokens(remove_punct = TRUE, # remove punctuation
         remove_numbers = TRUE, # remove numbers
         remove_symbols = TRUE) %>% # remove symbols
  tokens_tolower() # everything to lower cases
fashion_20_tokens <- fashion_20_tokens %>%
  tokens_remove(stopwords("english"))
## DFM
fashion_04_dfm <- dfm(fashion_04_tokens)
fashion_20_dfm <- dfm(fashion_20_tokens)
## 1D correspondence analysis
fashion_04_ca <- textmodel_ca(fashion_04_dfm)
fashion_20_ca <- textmodel_ca(fashion_20_dfm)
## 2D correspondence analysis
fashion_04_ca2 <- data.frame(dim1 = coef(fashion_04_ca, doc_dim = 1)$coef_document, 
                       dim2 = coef(fashion_04_ca, doc_dim = 2)$coef_document,
                       doc = fashion_04_ca$rownames)
fashion_20_ca2 <- data.frame(dim1 = coef(fashion_20_ca, doc_dim = 1)$coef_document, 
                       dim2 = coef(fashion_20_ca, doc_dim = 2)$coef_document,
                       doc = fashion_20_ca$rownames)
```


```{r Plot 2D correspondance analysis, echo = FALSE}
fashion_04_ca2 %>%
  ggplot(aes(x=dim1, y=dim2)) +
  geom_text(aes(label = doc)) +
  theme_classic() +
  labs(x="Dimension 1", y="Dimension 2") + ggtitle("2D Correspondance analysis 2004")

fashion_20_ca2 %>%
  ggplot(aes(x=dim1, y=dim2)) +
  geom_text(aes(label = doc)) +
  theme_classic() +
  labs(x="Dimension 1", y="Dimension 2") + ggtitle("2D Correspondance analysis 2020")
```

#### Collocation Analysis ####

```{r Tokenization, include = FALSE}
fashion_tokens <- fashion_corp %>%
  tokens(remove_punct = TRUE, # remove punctuation
         remove_numbers = TRUE, # remove numbers
         remove_symbols = TRUE,
         remove_url = TRUE) %>% # remove symbols
  tokens_tolower() # everything to lower cases
# takes some minutes!
words_to_be_removed <- c(stopwords("english"), "million", "fiscal", "january", "february",
           "march", "april", "may", "june", "july", "august", "september",
           "october", "november", "december", "business", "net", "s")
# //KEEP IN MIND// to update the list in the appendix of removed words
fashion_tokens <- fashion_tokens %>%
  tokens_remove(words_to_be_removed)
```

#### Dictionary evaluation ####


```{r Loading CSR dict, include = FALSE}
### Load CSR dict ###
dictionary_csr <- dictionary(file = "CorporateSocialResponsibility.cat")
# load the 1st dictionary CSR
fashion_CSR <- dfm(fashion_tokens, dictionary = dictionary_csr) # set up a dfm with word count by category
fashion_CSR <- convert(fashion_CSR, to = "data.frame") # convert it to df for easy merge
fashion_CSR <- cbind(fashion_CSR, fashion_10k[,c(1,3)]) # merge with cik and year data
count_tokens_fashion <- ntoken(fashion_tokens) #counts total tokens in the text
count_tokens_fashion <- as.data.frame(count_tokens_fashion) # convert to df for easy merge
fashion_CSR <- cbind(fashion_CSR, count_tokens_fashion) # merge with the token count
# find the relative ESG-related words 
fashion_CSR_total <- fashion_CSR %>% 
        select(ENVIRONMENT, EMPLOYEE, 'HUMAN RIGHTS', 'SOCIAL AND COMMUNITY') %>% 
        rowSums(na.rm=TRUE)
  
fashion_CSR <- cbind(fashion_CSR, fashion_CSR_total) 
rm(fashion_CSR_total)
  
fashion_CSR <- fashion_CSR %>% mutate(relative_env = ENVIRONMENT/count_tokens_fashion,
                                              relative_soc = `SOCIAL AND COMMUNITY`/count_tokens_fashion,
                                              relative_empl = EMPLOYEE/count_tokens_fashion,
                                              relative_humans = `HUMAN RIGHTS`/count_tokens_fashion,
                                              relative_overall = fashion_CSR_total/count_tokens_fashion)

round(mean(fashion_CSR$relative_env), digits = 4)*100
round(mean(fashion_CSR$relative_soc), digits = 4)*100
round(mean(fashion_CSR$relative_empl), digits = 4)*100
```


```{r Relative ESG wording CSR dict for fashion, echo = FALSE}
plot_ly(fashion_CSR, x = ~year, y = ~relative_env, type='scatter', mode='markers',
             text = ~paste("CIK :", cik,
                           "<br> Score :", paste0(round(100*relative_env, digits = 3), "%"), 
                           "<br> Year :", year),
             textposition = "auto",
             hoverinfo = "text") %>%
  
  add_trace(y = ~relative_humans, type='scatter', mode='markers',
             text = ~paste("CIK :", cik,
                           "<br> Score :", paste0(round(100*relative_humans, digits = 3), "%"), 
                           "<br> Year :", year),
             textposition = "auto",
             hoverinfo = "text") %>%
  
  add_trace(y = ~relative_empl, type='scatter', mode='markers',
             text = ~paste("CIK :", cik,
                           "<br> Score :", paste0(round(100*relative_empl, digits = 3), "%"), 
                           "<br> Year :", year),
             textposition = "auto",
             hoverinfo = "text") %>%
  layout(
    updatemenus = list(
      list(
        type = "buttons",
        x = -0.1,
        y = 0.8,
        label = 'Category',
        buttons = list(
          list(method = "restyle",
               args = list('visible', c(TRUE, TRUE, TRUE)),
               label = "View all"))), 
      list(type = "buttons",
        x = -0.1,
        y = 0.7,
        label = 'Category',
        buttons = list(
          list(method = "restyle",
               args = list('visible', c(TRUE, FALSE, FALSE)),
               label = "Environment"),
          list(method = "restyle",
               args = list('visible', c(FALSE, TRUE, FALSE)),
               label = "Society"),
          list(method = "restyle",
               args = list('visible', c(FALSE, FALSE, TRUE)),
               label = "Employees"))))) %>%      
      layout(title = 'ESG wording. Fashion industry. CSR dictionary',
              xaxis = list(title = 'year'),
              yaxis = list(title = 'percentage', hoverformat = '.2f'), showlegend = FALSE) 

```


//BBK dict //

With the increasing importance of environmental, social and governance (ESG) factors for companies and investors, Baier, Berninger and Kiesel (2020) have recently developed a new ESG content dictionary. The dictionary was trained on the basis of financial reports and is intended as a tool to reflect the ESG activities of companies. Each of the 482 words occurring in the dictionary is considered as a ESG-term that is mainly used in the context of ESG. The index consists of three main topics: governance, environmental and social. Further there are 11 categories and 35 subcategories that allows a very precise search for different aspects in the field of ESG.

reference:
- Baier, Berninger & Kiesel (2020)

```{r Loading BBK dict, include = FALSE}
### Load BBK dict ###
dictionary_bbk <- read_excel(here("BaierBerningerKiesel.xlsx"), sheet = "Sheet1", col_names = TRUE)
# load the 2nd dictionary BBK Excel-file
Governance_BBK <- dictionary_bbk[dictionary_bbk$Topic == 'Governance',]
Governance_BBK <- Governance_BBK[1]
Environmental_BBK <- dictionary_bbk[dictionary_bbk$Topic == 'Environmental',]
Environmental_BBK <- Environmental_BBK[1]
Social_BBK <- dictionary_bbk[dictionary_bbk$Topic == 'Social',]
Social_BBK <- Social_BBK[1]
dictionary_BBK <- dictionary(list(Governance = Governance_BBK, 
                                  Environmental = Environmental_BBK, 
                                  Social = Social_BBK))
rm(Governance_BBK, Environmental_BBK, Social_BBK)
fashion_BBK <- dfm(fashion_tokens, dictionary = dictionary_BBK, valuetype = "glob") # set up a dfm with word count by category
fashion_BBK <- convert(fashion_BBK, to = "data.frame") # convert it to df for easy merge
fashion_BBK <- cbind(fashion_BBK, fashion_10k[,c(1,3)]) # merge with cik and year data
fashion_BBK <- cbind(fashion_BBK, count_tokens_fashion) # merge with the token count
# fashion_BBK$year <- as.Date(fashion_BBK$year, format="%d/%m/%Y") 
# find the relative ESG-related words 
total_ESG_only_BBK <- fashion_BBK %>% 
  select(Governance.Word, Environmental.Word, Social.Word) %>% 
  rowSums(na.rm=TRUE)
fashion_BBK <- cbind(fashion_BBK, total_ESG_only_BBK) 
fashion_BBK <- fashion_BBK %>% mutate(relative_govern = Governance.Word/count_tokens_fashion,
                                      relative_env = Environmental.Word/count_tokens_fashion,
                                      relative_soc = Social.Word/count_tokens_fashion,
                                      relative_overall = total_ESG_only_BBK/count_tokens_fashion)

round(mean(fashion_BBK$relative_env), digits = 4)*100
round(mean(fashion_BBK$relative_soc), digits = 4)*100
round(mean(fashion_BBK$relative_govern), digits = 4)*100

```

One widely used and cited content dictionary was developed by Penlce and Mălăescu (2016) to measure the corporate social responsibility (CSR) of text documents issued by a company. The dictionary is quite comprehensive and consists of 1428 entries across four dimensions: Human Rights (297), Employee (319), Social and Community (361) and Environment (451). However, it is notable that different words can occur in multiple dimensions, as for example the term "abuse" is contained in all four dimensions. Some words might not always be ESG-specific. This is the reason why an alternative, second dictionary was used. Baier, Berninger and Kiesel (2020) have recently developed a new ESG content dictionary (BBK) on the basis of financial reports to reflect the ESG activities of companies. This second dictionary focus only on terms exclusively related to ESG and contains only a third of the amount of entries compared to CSR. The fact that also BBK has specific categories enables a is precisely evaluation of different aspects in the field of ESG. The entries in each categores are distributed as following:  Environmental (55), Social (151) and Governance (276). What is noticeable is the uneven distribution of entries in which the category environment has significantly less terms than the other. Figure X shows the relative occurrence of average ESG wording in the 10-Ks for each industry sample across the two dictionaries on bases of tokens (after tokenization process):		

```{r comparison table token appearance, echo = FALSE}		
tab <- matrix(c(round(mean(fashion_CSR$relative_env), digits = 4)*100, round(mean(fashion_BBK$relative_env), digits = 4)*100, round(mean(fashion_CSR$relative_soc), digits = 4)*100, round(mean(fashion_BBK$relative_soc), digits = 4)*100, round(mean(fashion_CSR$relative_empl), digits = 4)*100, round(mean(fashion_BBK$relative_govern), digits = 4)*100, round(mean(energy_CSR$relative_env), digits = 4)*100, round(mean(energy_BBK$relative_env), digits = 4)*100, round(mean(energy_CSR$relative_soc), digits = 4)*100, round(mean(energy_BBK$relative_soc), digits = 4)*100, round(mean(energy_CSR$relative_empl), digits = 4)*100, round(mean(energy_BBK$relative_govern), digits = 4)*100, round(mean(bev_CSR$relative_env), digits = 4)*100, round(mean(bev_BBK$relative_env), digits = 4)*100, round(mean(bev_CSR$relative_soc), digits = 4)*100, round(mean(bev_BBK$relative_soc), digits = 4)*100, round(mean(bev_CSR$relative_empl), digits = 4)*100, round(mean(bev_BBK$relative_govern), digits = 4)*100), ncol=6, nrow =3, byrow=TRUE)		
rownames(tab) <- c("Fashion","Energy","Beverages")		
colnames(tab) <- c("Environment (CSR)","Environment (BBK)","Social (CSR)", "Social (BBK)", "Governance (CSR)", "Governance (BBK)")		
tab <- as.table(tab)		
tab %>%		
  kbl(caption = "Comparison of Relative Occurence of Average ESG Wording in 10-K after Tokenization Process [in %]") %>%		
  kable_styling()		
```	

As expected the CSR dictionary captures much more tokens than the BBK dictionary. For both dictionaries most environment tokens did occur in 10-Ks of energy companies, followed by the beverage industry. Also, for Governance both dictionaries do measure the same differences between the three industry samples. However, for the number of ESG-related tokens in the dimension of Social the dictionaries do not correspond. Due to these differences it is useful to check the key drivers of each dictionary to see if it captures the right wording for the purpose of the analysis. From Appendix 3 it can be seen that the most frequently occurring terms in for the CSR dictionary are not necessarily indicating ESG activities. It seems only reasonable that words such as "management", "rate", or "equity" (all entries in the governance respectively employee category) occur frequently in an annual report. The same applies to the word "common", one of the most captured words by the dimension Social across all industries. This can be avoided when choosing a dictionary with very specific terms that are ESG-related with less potential of ambiguity. This was the intention to do so with the BBK dict.		```{r Relative ESG wording BBK dict for fashion, echo = FALSE}
A detailed examination (Appendix 2) of the BBK dictionary tokens reveals that there are fewer key drivers as for the CSR dictionary. The polarity tokens are better distributed among different terms. In general, the key drivers are more focused on ESG activities. Nevertheless, there are some individual terms that also occur very often in BBK and dominate. This does not mean anything bad per se but for the beverage sample, where the terms "water" and "alcohol" are very prominent independently from ESG activities. This should be kept in mind when analyzing the beverage sample with the BBK dictionary. Apart from that, the examination of the dictionaries shows a more satisfactory result for BBK. Therefore, we will mainly work with BBK in the following. However, one problem that remains more generally, regardless of the choice of dictionary, is that for obvious reasons energy companies achieve increased environmental activity due to the polarization of environmental terms. However, most word usages will only describe their daily business rather than write extensively about their ESG activities.

```{r Relative ESG wording BBK dict for fashion, echo = FALSE}

plot_ly(fashion_BBK, x = ~year, y = ~relative_env, type='scatter', mode='markers',
             text = ~paste("CIK :", cik,
                           "<br> Score :", paste0(round(100*relative_env, digits = 3), "%"), 
                           "<br> Year :", year),
             textposition = "auto",
             hoverinfo = "text") %>%
  
  add_trace(y = ~relative_soc, type='scatter', mode='markers',
             text = ~paste("CIK :", cik,
                           "<br> Score :", paste0(round(100*relative_soc, digits = 3), "%"), 
                           "<br> Year :", year),
             textposition = "auto",
             hoverinfo = "text") %>%
  
  add_trace(y = ~relative_govern, type='scatter', mode='markers',
             text = ~paste("CIK :", cik,
                           "<br> Score :", paste0(round(100*relative_govern, digits = 3), "%"), 
                           "<br> Year :", year),
             textposition = "auto",
             hoverinfo = "text") %>%
  layout(
    updatemenus = list(
      list(
        type = "buttons",
        x = -0.1,
        y = 0.8,
        label = 'Category',
        buttons = list(
          list(method = "restyle",
               args = list('visible', c(TRUE, TRUE, TRUE)),
               label = "View all"))), 
      list(type = "buttons",
        x = -0.1,
        y = 0.7,
        label = 'Category',
        buttons = list(
          list(method = "restyle",
               args = list('visible', c(TRUE, FALSE, FALSE)),
               label = "Environment"),
          list(method = "restyle",
               args = list('visible', c(FALSE, TRUE, FALSE)),
               label = "Society"),
          list(method = "restyle",
               args = list('visible', c(FALSE, FALSE, TRUE)),
               label = "Governance"))))) %>%      
      layout(title = 'ESG wording. Fashion industry. BBK dictionary',
              xaxis = list(title = 'year'),
              yaxis = list(title = 'percentage', hoverformat = '.2%'), showlegend = FALSE) 

```


#### Comparison with ESG-Ratings ####
Since our goal is to analyse whether 10-k reports carry valuable information regarding the company's ESG values, we further compare the ESG ratings received by the companies to the relative ESG sentiment from the 10-k report. 

We conduct the analysis on token level, and not aggregated, to see whether some ESG-related words words appear particularly frequently.

``` {r Read file with ESG scores, include = FALSE}
ESG_scores_fashion <- read_excel(here("ESG_scores_fashion.xlsx"), sheet = "ESG", col_names = TRUE)
names(ESG_scores_fashion)[4] <- "cik" #rename the cik column for convenience
ESG_scores_fashion$cik <- as.character(ESG_scores_fashion$cik)

ESG_scores_fashion_rf <- ESG_scores_fashion[,c(4,15:32)]

for (i in 2:19) { # rename the columns as years
names(ESG_scores_fashion_rf)[i] <- paste0(2023-i)}

ESG_scores_fashion_rf_panel <- NULL 

for (i in 1:nrow(ESG_scores_fashion_rf)) {
  df <- ESG_scores_fashion_rf[i,]
  df <- t(df)
  df <- as.data.frame(df)
  df <- df %>% mutate(cik = df[1,1])
  df <- df[-1,]
  df$year <- rownames(df)
  ESG_scores_fashion_rf_panel <- rbind(ESG_scores_fashion_rf_panel, df)
}

plot_ly(data = ESG_scores_fashion_rf_panel, x = ~year, y = ~V1, color = ~cik) %>% 
      add_markers() %>%      
      layout(title = 'ESG rating evolution. Fashion',
              xaxis = list(title = 'year'),
              yaxis = list(title = 'rating', tickformat = '.0',hoverformat = '.2f'))

ESG_scores_fashion_rf_panel <- merge(ESG_scores_fashion_rf_panel, fashion_BBK, by = c("cik", "year"))

ESG_scores_fashion_rf_panel <- as.data.frame(ESG_scores_fashion_rf_panel)
names(ESG_scores_fashion_rf_panel)[3] <- "rating"
ESG_scores_fashion_rf_panel$rating <- as.numeric(ESG_scores_fashion_rf_panel$rating)
ESG_scores_fashion_rf_panel <- na.omit(ESG_scores_fashion_rf_panel)


ESG_scores_fashion_rf_panel_plot <- ESG_scores_fashion_rf_panel %>% group_by(year) %>%
                                          summarise(mean_rating = median(rating),
                                          mean_total = median(relative_env))

# not 100% sure if we need this graph, since it's the average by year, which is not too informative
esg_scores_fashion <- plot_ly(ESG_scores_fashion_rf_panel_plot, x = ~year, y = ~mean_rating, type = "scatter", name = "ESG rating") %>%
  add_trace(x = ~year, y = ~mean_total, type = "scatter", yaxis = "y2", name = "ESG wording") %>%
  layout(yaxis2 = list(overlaying = "y", side = "right"))
```


```{r Wordcloud CSR dictionary for fashion, echo = FALSE}
### Select CSR dictionary tokens ###
## selecting tokens
fashion_csr_all_tokens <- tokens_select(fashion_tokens, dictionary_csr)
fashion_csr_hum_tokens <- tokens_select(fashion_tokens, dictionary_csr$`HUMAN RIGHTS`)
fashion_csr_emp_tokens <- tokens_select(fashion_tokens, dictionary_csr$EMPLOYEE)
fashion_csr_soc_tokens <- tokens_select(fashion_tokens, dictionary_csr$`SOCIAL AND COMMUNITY`)
fashion_csr_env_tokens <- tokens_select(fashion_tokens, dictionary_csr$ENVIRONMENT)
## creating dfm
fashion_dfm <- dfm(fashion_tokens)
fashion_csr_all_dfm <- dfm(fashion_csr_all_tokens)
fashion_csr_hum_dfm <- dfm(fashion_csr_hum_tokens)
fashion_csr_emp_dfm <- dfm(fashion_csr_emp_tokens)
fashion_csr_soc_dfm <- dfm(fashion_csr_soc_tokens)
fashion_csr_env_dfm <- dfm(fashion_csr_env_tokens)
## count token
fashion_count_tokens <- ntoken(fashion_dfm)
##

# wordcloud for most used words in the CSR dictionary
textplot_wordcloud(fashion_csr_all_dfm, max_words = 100,
                   color = c("grey80", "darkgoldenrod1", "tomato"))

textplot_wordcloud(fashion_csr_env_dfm, max_words = 100,color = c("grey80", "darkgoldenrod1", "tomato"))
textplot_wordcloud(fashion_csr_soc_dfm, max_words = 100,color = c("grey80", "darkgoldenrod1", "tomato"))
textplot_wordcloud(fashion_csr_emp_dfm, max_words = 100,color = c("grey80", "darkgoldenrod1", "tomato"))
```


```{r Wordcloud BBK fashion}
fashion_bbk_env_tokens <- tokens_select(fashion_tokens, dictionary_BBK$Environmental$Word)
fashion_bbk_soc_tokens <- tokens_select(fashion_tokens, dictionary_BBK$Social$Word)
fashion_bbk_gov_tokens <- tokens_select(fashion_tokens, dictionary_BBK$Governance$Word)

fashion_bbk_env_dfm <- dfm(fashion_bbk_env_tokens)
fashion_bbk_soc_dfm <- dfm(fashion_bbk_soc_tokens)
fashion_bbk_gov_dfm <- dfm(fashion_bbk_gov_tokens)

textplot_wordcloud(fashion_bbk_env_dfm, max_words = 100,color = c("grey80", "darkgoldenrod1", "tomato"))
textplot_wordcloud(fashion_bbk_soc_dfm, max_words = 100,color = c("grey80", "darkgoldenrod1", "tomato"))
textplot_wordcloud(fashion_bbk_gov_dfm, max_words = 100,color = c("grey80", "darkgoldenrod1", "tomato"))
```

```{r add data for market parameters, include = FALSE}

fashion_market_data <- read_excel(here("revenue_figures.xlsx"), sheet = "fashion", col_names = TRUE)

names(fashion_market_data)[3] <- "cik" #rename the cik column for convenience
fashion_market_data$cik <- as.character(fashion_market_data$cik)

for (i in 10:27) { # rename the columns as years
names(fashion_market_data)[i] <- paste0(2031-i)}
fashion_market_data_capex <- fashion_market_data[c(3, 10:27)]

fashion_all_data_capex <- NULL 

for (i in 1:nrow(fashion_market_data_capex)) {
  df <- fashion_market_data_capex[i,]
  df <- t(df)
  df <- as.data.frame(df)
  df <- df %>% mutate(cik = df[1,1])
  df <- df[-1,]
  df$year <- rownames(df)
  fashion_all_data_capex <- rbind(fashion_all_data_capex, df)
}

names(fashion_all_data_capex)[1] <- "capex"

# repeat the same to get prices 
for (i in 28:45) { # rename the columns as years
names(fashion_market_data)[i] <- paste0(2049-i)}
fashion_market_data_prices <- fashion_market_data[c(3, 28:45)]

fashion_all_data_prices <- NULL 

for (i in 1:nrow(fashion_market_data_prices)) {
  df <- fashion_market_data_prices[i,]
  df <- t(df)
  df <- as.data.frame(df)
  df <- df %>% mutate(cik = df[1,1])
  df <- df[-1,]
  df$year <- rownames(df)
  fashion_all_data_prices <- rbind(fashion_all_data_prices, df)
}

names(fashion_all_data_prices)[1] <- "share_price"

# and revenues
for (i in 46:63) { # rename the columns as years
names(fashion_market_data)[i] <- paste0(2067-i)}
fashion_market_data_revenues <- fashion_market_data[c(3, 46:63)]

fashion_all_data_revenues <- NULL 

for (i in 1:nrow(fashion_market_data_revenues)) {
  df <- fashion_market_data_revenues[i,]
  df <- t(df)
  df <- as.data.frame(df)
  df <- df %>% mutate(cik = df[1,1])
  df <- df[-1,]
  df$year <- rownames(df)
  fashion_all_data_revenues <- rbind(fashion_all_data_revenues, df)
}

names(fashion_all_data_revenues)[1] <- "revenues"

fashion_regression_df <- merge(fashion_all_data_revenues, fashion_all_data_capex, by = c("cik", "year"))
fashion_regression_df <- fashion_regression_df %>% merge(fashion_all_data_prices, by = c("cik", "year"))
fashion_regression_df <- fashion_regression_df %>% merge(ESG_scores_fashion_rf_panel, by = c("cik", "year"))
fashion_regression_df <- fashion_regression_df %>% mutate(industry = "fashion")
```
#### Energy sector companies #######

We further repeat the analysis on a sample of 30 randomly chosen energy sector companies.

```{r Loading files for energy companies, include = FALSE}
# load excel files with cik numbers for each industry with the companies
energy <- read_excel(here("energy_cik.xlsx"), sheet = "Sheet1", col_names = TRUE)
energy <- energy[, c(1, 4:14)]
# keeping only the cik number
energy_cik <- energy$CIK
energy_cik<-as.data.frame(energy_cik)
# load the 10Ks from downloaded files
energy_10k <- NULL
# loop that collects all reports for all companies for each industry
# this will take some minutes!!!
for (i in energy_cik) {
  output <- readtext(here("energy_10k", i))
  energy_10k <- rbind(energy_10k, output)
}
rm(output)
# simple cleaning
energy_10k$text <- str_remove_all(energy_10k$text, "\n•")
energy_10k$text <- str_remove_all(energy_10k$text, "\n")
# define columns into cik, report type and report year
energy_10k <- separate(
  energy_10k,
  1,
  into = c("cik", "type", "year", NA),
  sep = "_",
  remove = TRUE)
# only keep year
#keep the year and not the full date
energy_10k <- separate(
  energy_10k,
  "year",
  into = c("year", NA),
  sep = "-",
  remove = TRUE)
```

```{r Creating a Corpus for energy companies, include = FALSE}
energy_corp <- corpus(energy_10k)
energy_tokens <- energy_corp %>%
  tokens(remove_punct = TRUE, # remove punctuation
         remove_numbers = TRUE, # remove numbers
         remove_symbols = TRUE,
         remove_url = TRUE) %>% # remove symbols
  tokens_tolower() # everything to lower cases
# takes some minutes!
words_to_be_removed <- c(stopwords("english"), "million", "fiscal", "january", "february",
           "march", "april", "may", "june", "july", "august", "september",
           "october", "november", "december", "business", "net", "s")
# //KEEP IN MIND// to update the list in the appendix of removed words
energy_tokens <- energy_tokens %>%
  tokens_remove(words_to_be_removed)
# apply Flesch readability measure (takes a few minutes)
energy_rd_flesch <- energy_corp %>%
  textstat_readability(measure = "Flesch", remove_hyphens = TRUE)
# apply FOG readability measure (takes a few minutes)
energy_rd_fog <- energy_corp %>%
  textstat_readability(measure = "FOG", remove_hyphens = TRUE)
```

The plot shows that the calculated complexity by Flesch increases and becomes increasingly similar. The same was preceived for the sample of fashion companies before. There is no significant difference in the readability comparing the fashion and the enegry sample. The average Flesch readability score at around `r round(mean(energy_rd_flesch$Flesch), digits = 2)` for the energy companies is nearly the same as for the fashion sample. Both scores indicating very complex and difficult to read text sources. However, for the energy sample it tends to have few more outliers.

```{r Plot readability Flesch for energy, echo=FALSE}
# all companies, all years
plot_flesch_energy <- ggplotly(ggplot(energy_rd_flesch, aes(x=energy_10k$year, y =Flesch, colour=energy_10k$cik)) + geom_point() +  ggtitle("Flesch - Readability for energy companies"), tooltip = c("colour", "y", "x") )

x <- list(
    title = "year")

y <- list(
    title = "Readability score")

plot_flesch_energy %>% layout(xaxis = x, yaxis = y)

```

Also regarding the average FOG score for our sample of 30 energy companies from the US which is at around `r round(mean(energy_rd_fog$FOG), digits = 2)` it scores very similar as the average for the fashion companies. The same picture about the trend is seen. Also the ouliers within the enegry companies do persist the FOG measure. By further examination of the outlier 10-Ks we do not find any untypical nature of text.

```{r Readability plots FOG for energy, echo = FALSE, fig.width = 10 , fig.fullwidth=TRUE}
# all companies, all years
plot_flesch_energy_fog <- ggplotly(ggplot(energy_rd_fog, aes(x=energy_10k$year, y =FOG, colour=energy_10k$cik)) + geom_point() +  ggtitle("FOG - Readability for energy companies"), tooltip = c("colour", "y", "x") )

x <- list(
    title = "year")

y <- list(
    title = "Readability score")

plot_flesch_energy_fog %>% layout(xaxis = x, yaxis = y)
rm(x,y)
```

```{r Correspondance analysis 2004 and 2020 energy, include = FALSE}
# analysis only on one year across companies to have only max 27 data points (otherwise way too much)
# filter out the years 2004 and 2020 to show difference in correspondance
energy_2004 <- energy_10k %>%
  filter(year == 2004)
energy_2020 <- energy_10k %>%
  filter(year == 2020)
## create corpus
energy_04_corp <- corpus(energy_2004)
energy_20_corp <- corpus(energy_2020)
## Tokenization
energy_04_tokens <- energy_04_corp %>%
  tokens(remove_punct = TRUE, # remove punctuation
         remove_numbers = TRUE, # remove numbers
         remove_symbols = TRUE) %>% # remove symbols
  tokens_tolower() # everything to lower cases
energy_04_tokens <- energy_04_tokens %>%
  tokens_remove(stopwords("english"))
energy_20_tokens <- energy_20_corp %>%
  tokens(remove_punct = TRUE, # remove punctuation
         remove_numbers = TRUE, # remove numbers
         remove_symbols = TRUE) %>% # remove symbols
  tokens_tolower() # everything to lower cases
energy_20_tokens <- energy_20_tokens %>%
  tokens_remove(stopwords("english"))
## DFM
energy_04_dfm <- dfm(energy_04_tokens)
energy_20_dfm <- dfm(energy_20_tokens)
## 1D correspondence analysis
energy_04_ca <- textmodel_ca(energy_04_dfm)
energy_20_ca <- textmodel_ca(energy_20_dfm)
## 2D correspondence analysis
energy_04_ca2 <- data.frame(dim1 = coef(energy_04_ca, doc_dim = 1)$coef_document, 
                       dim2 = coef(energy_04_ca, doc_dim = 2)$coef_document,
                       doc = energy_04_ca$rownames)
energy_20_ca2 <- data.frame(dim1 = coef(energy_20_ca, doc_dim = 1)$coef_document, 
                       dim2 = coef(energy_20_ca, doc_dim = 2)$coef_document,
                       doc = energy_20_ca$rownames)
energy_04_plot <- energy_04_ca2 %>%
  ggplot(aes(x=dim1, y=dim2)) +
  geom_text(aes(label = doc)) +
  theme_classic() +
  labs(x="Dimension 1", y="Dimension 2") + ggtitle("2D Correspondance analysis 2004")
energy_20_plot <- energy_20_ca2 %>%
  ggplot(aes(x=dim1, y=dim2)) +
  geom_text(aes(label = doc)) +
  theme_classic() +
  labs(x="Dimension 1", y="Dimension 2") + ggtitle("2D Correspondance analysis 2020")
```


```{r Apply CSR dict for energy, include = FALSE}
energy_CSR <- dfm(energy_tokens, dictionary = dictionary_csr) # set up a dfm with word count by category
energy_CSR <- convert(energy_CSR, to = "data.frame") # convert it to df for easy merge
energy_CSR <- cbind(energy_CSR, energy_10k[,c(1,3)]) # merge with cik and year data
count_tokens_energy <- ntoken(energy_tokens) #counts total tokens in the text
count_tokens_energy <- as.data.frame(count_tokens_energy) # convert to df for easy merge
energy_CSR <- cbind(energy_CSR, count_tokens_energy) # merge with the token count
# find the relative ESG-related words 
energy_CSR_total <- energy_CSR %>% 
        select(ENVIRONMENT, EMPLOYEE, 'HUMAN RIGHTS', 'SOCIAL AND COMMUNITY') %>% 
        rowSums(na.rm=TRUE)
  
energy_CSR <- cbind(energy_CSR, energy_CSR_total) 
rm(energy_CSR_total)
  
energy_CSR <- energy_CSR %>% mutate(relative_env = ENVIRONMENT/count_tokens_energy,
                                    relative_soc = `SOCIAL AND COMMUNITY`/count_tokens_energy,
                                    relative_empl = EMPLOYEE/count_tokens_energy,
                                    relative_humans = `HUMAN RIGHTS`/count_tokens_energy,
                                    relative_overall = energy_CSR_total/count_tokens_energy)
round(mean(energy_CSR$relative_env), digits = 4)*100
round(mean(energy_CSR$relative_soc), digits = 4)*100
round(mean(energy_CSR$relative_empl), digits = 4)*100
```

```{r Relative ESG wording CSR dict for energy, echo = FALSE}
plot_ly(energy_CSR, x = ~year, y = ~relative_env, type='scatter', mode='markers',
             text = ~paste("CIK :", cik,
                           "<br> Score :", paste0(round(100*relative_env, digits = 3), "%"), 
                           "<br> Year :", year),
             textposition = "auto",
             hoverinfo = "text") %>%
  
  add_trace(y = ~relative_humans, type='scatter', mode='markers',
             text = ~paste("CIK :", cik,
                           "<br> Score :", paste0(round(100*relative_humans, digits = 3), "%"), 
                           "<br> Year :", year),
             textposition = "auto",
             hoverinfo = "text") %>%
  
  add_trace(y = ~relative_empl, type='scatter', mode='markers',
             text = ~paste("CIK :", cik,
                           "<br> Score :", paste0(round(100*relative_empl, digits = 3), "%"), 
                           "<br> Year :", year),
             textposition = "auto",
             hoverinfo = "text") %>%
  layout(
    updatemenus = list(
      list(
        type = "buttons",
        x = -0.1,
        y = 0.8,
        label = 'Category',
        buttons = list(
          list(method = "restyle",
               args = list('visible', c(TRUE, TRUE, TRUE)),
               label = "View all"))), 
      list(type = "buttons",
        x = -0.1,
        y = 0.7,
        label = 'Category',
        buttons = list(
          list(method = "restyle",
               args = list('visible', c(TRUE, FALSE, FALSE)),
               label = "Environment"),
          list(method = "restyle",
               args = list('visible', c(FALSE, TRUE, FALSE)),
               label = "Society"),
          list(method = "restyle",
               args = list('visible', c(FALSE, FALSE, TRUE)),
               label = "Employees"))))) %>%      
      layout(title = 'ESG wording. Energy industry. CSR dictionary',
              xaxis = list(title = 'year'),
              yaxis = list(title = 'percentage', hoverformat = '.2f'), showlegend = FALSE) 

```

```{r Wordcloud CSR dictionary for energy, echo = FALSE}
### Select CSR dictionary tokens ###
## selecting tokens
energy_CSR_all_tokens <- tokens_select(energy_tokens, dictionary_csr)
energy_CSR_hum_tokens <- tokens_select(energy_tokens, dictionary_csr$`HUMAN RIGHTS`)
energy_CSR_emp_tokens <- tokens_select(energy_tokens, dictionary_csr$EMPLOYEE)
energy_CSR_soc_tokens <- tokens_select(energy_tokens, dictionary_csr$`SOCIAL AND COMMUNITY`)
energy_CSR_env_tokens <- tokens_select(energy_tokens, dictionary_csr$ENVIRONMENT)
energy_BBK_all_tokens <- tokens_select(energy_tokens, dictionary_bbk$Topic=="Governance")
## creating dfm
energy_dfm <- dfm(energy_tokens)
energy_CSR_all_dfm <- dfm(energy_CSR_all_tokens)
energy_CSR_hum_dfm <- dfm(energy_CSR_hum_tokens)
energy_CSR_emp_dfm <- dfm(energy_CSR_emp_tokens)
energy_CSR_soc_dfm <- dfm(energy_CSR_soc_tokens)
energy_CSR_env_dfm <- dfm(energy_CSR_env_tokens)
energy_BBK_all_dfm <- dfm(energy_BBK_all_tokens)
## count token
energy_count_tokens <- ntoken(energy_dfm)
# wordcloud for most used words in the CSR dictionary
textplot_wordcloud(energy_CSR_all_dfm, max_words = 100,
                   color = c("grey80", "darkgoldenrod1", "tomato"))

textplot_wordcloud(energy_CSR_env_dfm, max_words = 100,color = c("grey80", "darkgoldenrod1", "tomato"))
textplot_wordcloud(energy_CSR_soc_dfm, max_words = 100,color = c("grey80", "darkgoldenrod1", "tomato"))
textplot_wordcloud(energy_CSR_emp_dfm, max_words = 100,color = c("grey80", "darkgoldenrod1", "tomato"))

```

```{r Wordcloud BBK energy}
energy_bbk_env_tokens <- tokens_select(energy_tokens, dictionary_BBK$Environmental$Word)
energy_bbk_soc_tokens <- tokens_select(energy_tokens, dictionary_BBK$Social$Word)
energy_bbk_gov_tokens <- tokens_select(energy_tokens, dictionary_BBK$Governance$Word)

energy_bbk_env_dfm <- dfm(energy_bbk_env_tokens)
energy_bbk_soc_dfm <- dfm(energy_bbk_soc_tokens)
energy_bbk_gov_dfm <- dfm(energy_bbk_gov_tokens)

textplot_wordcloud(energy_bbk_env_dfm, max_words = 100,color = c("grey80", "darkgoldenrod1", "tomato"))
textplot_wordcloud(energy_bbk_soc_dfm, max_words = 100,color = c("grey80", "darkgoldenrod1", "tomato"))
textplot_wordcloud(energy_bbk_gov_dfm, max_words = 100,color = c("grey80", "darkgoldenrod1", "tomato"))
```

```{r Preparation relative ESG wording BBK dict for energy, inlcude = FALSE}
energy_BBK <- dfm(energy_tokens, dictionary = dictionary_BBK, valuetype = "glob") # set up a dfm with word count by category
energy_BBK <- convert(energy_BBK, to = "data.frame") # convert it to df for easy merge
energy_BBK <- cbind(energy_BBK, energy_10k[,c(1,3)]) # merge with cik and year data
energy_BBK <- cbind(energy_BBK, count_tokens_energy) # merge with the token count
# energy_BBK$year <- as.Date(energy_BBK$year, format="%d/%m/%Y") 
# find the relative ESG-related words 
total_ESG_only_BBK <- energy_BBK %>% 
  select(Governance.Word, Environmental.Word, Social.Word) %>% 
  rowSums(na.rm=TRUE)
energy_BBK <- cbind(energy_BBK, total_ESG_only_BBK) 
energy_BBK <- energy_BBK %>% mutate(relative_govern = Governance.Word/count_tokens_energy,
                                      relative_env = Environmental.Word/count_tokens_energy,
                                      relative_soc = Social.Word/count_tokens_energy,
                                      relative_overall = total_ESG_only_BBK/count_tokens_energy)
round(mean(energy_BBK$relative_env), digits = 4)*100
round(mean(energy_BBK$relative_soc), digits = 4)*100
round(mean(energy_BBK$relative_soc), digits = 4)*100
round(mean(energy_BBK$relative_govern), digits = 4)*100
```

```{r Relative ESG wording BBK dict for energy, include = TRUE}

plot_ly(energy_BBK, x = ~year, y = ~relative_env, type='scatter', mode='markers',
             text = ~paste("CIK :", cik,
                           "<br> Score :", paste0(round(100*relative_env, digits = 3), "%"), 
                           "<br> Year :", year),
             textposition = "auto",
             hoverinfo = "text") %>%
  
  add_trace(y = ~relative_soc, type='scatter', mode='markers',
             text = ~paste("CIK :", cik,
                           "<br> Score :", paste0(round(100*relative_soc, digits = 3), "%"), 
                           "<br> Year :", year),
             textposition = "auto",
             hoverinfo = "text") %>%
  
  add_trace(y = ~relative_govern, type='scatter', mode='markers',
             text = ~paste("CIK :", cik,
                           "<br> Score :", paste0(round(100*relative_govern, digits = 3), "%"), 
                           "<br> Year :", year),
             textposition = "auto",
             hoverinfo = "text") %>%
  layout(
    updatemenus = list(
      list(
        type = "buttons",
        x = -0.1,
        y = 0.8,
        label = 'Category',
        buttons = list(
          list(method = "restyle",
               args = list('visible', c(TRUE, TRUE, TRUE)),
               label = "View all"))), 
      list(type = "buttons",
        x = -0.1,
        y = 0.7,
        label = 'Category',
        buttons = list(
          list(method = "restyle",
               args = list('visible', c(TRUE, FALSE, FALSE)),
               label = "Environment"),
          list(method = "restyle",
               args = list('visible', c(FALSE, TRUE, FALSE)),
               label = "Society"),
          list(method = "restyle",
               args = list('visible', c(FALSE, FALSE, TRUE)),
               label = "Governance"))))) %>%      
      layout(title = 'ESG wording. Energy industry. BBK dictionary',
              xaxis = list(title = 'year'),
              yaxis = list(title = 'percentage', hoverformat = '.2%'), showlegend = FALSE) 
```
``` {r Read file with ESG scores Energy, include = FALSE}
ESG_scores_energy <- read_excel(here("ESG_scores_energy.xlsx"), sheet = "ESG", col_names = TRUE)
names(ESG_scores_energy)[3] <- "cik" #rename the cik column for convenience
ESG_scores_energy$cik <- as.character(ESG_scores_energy$cik)

ESG_scores_energy_rf <- ESG_scores_energy[,c(3,13:30)]

for (i in 2:19) { # rename the columns as years
names(ESG_scores_energy_rf)[i] <- paste0(2023-i)}

ESG_scores_energy_rf_panel <- NULL 

for (i in 1:nrow(ESG_scores_energy_rf)) {
  df <- ESG_scores_energy_rf[i,]
  df <- t(df)
  df <- as.data.frame(df)
  df <- df %>% mutate(cik = df[1,1])
  df <- df[-1,]
  df$year <- rownames(df)
  ESG_scores_energy_rf_panel <- rbind(ESG_scores_energy_rf_panel, df)
}


ESG_scores_energy_rf_panel <- merge(ESG_scores_energy_rf_panel, energy_BBK, by = c("cik", "year"))

ESG_scores_energy_rf_panel <- as.data.frame(ESG_scores_energy_rf_panel)
names(ESG_scores_energy_rf_panel)[3] <- "rating"
ESG_scores_energy_rf_panel$rating <- as.numeric(ESG_scores_energy_rf_panel$rating)
ESG_scores_energy_rf_panel <- na.omit(ESG_scores_energy_rf_panel)

```

```{r add data for market parameters Energy, include = FALSE}

energy_market_data <- read_excel(here("revenue_figures.xlsx"), sheet = "energy", col_names = TRUE)

names(energy_market_data)[3] <- "cik" #rename the cik column for convenience
energy_market_data$cik <- as.character(energy_market_data$cik)

for (i in 10:27) { # rename the columns as years
names(energy_market_data)[i] <- paste0(2031-i)}
energy_market_data_capex <- energy_market_data[c(3, 10:27)]

energy_all_data_capex <- NULL 

for (i in 1:nrow(energy_market_data_capex)) {
  df <- energy_market_data_capex[i,]
  df <- t(df)
  df <- as.data.frame(df)
  df <- df %>% mutate(cik = df[1,1])
  df <- df[-1,]
  df$year <- rownames(df)
  energy_all_data_capex <- rbind(energy_all_data_capex, df)
}

names(energy_all_data_capex)[1] <- "capex"

# repeat the same to get prices 
for (i in 28:45) { # rename the columns as years
names(energy_market_data)[i] <- paste0(2049-i)}
energy_market_data_prices <- energy_market_data[c(3, 28:45)]

energy_all_data_prices <- NULL 

for (i in 1:nrow(energy_market_data_prices)) {
  df <- energy_market_data_prices[i,]
  df <- t(df)
  df <- as.data.frame(df)
  df <- df %>% mutate(cik = df[1,1])
  df <- df[-1,]
  df$year <- rownames(df)
  energy_all_data_prices <- rbind(energy_all_data_prices, df)
}

names(energy_all_data_prices)[1] <- "share_price"

# and revenues
for (i in 46:63) { # rename the columns as years
names(energy_market_data)[i] <- paste0(2067-i)}
energy_market_data_revenues <- energy_market_data[c(3, 46:63)]

energy_all_data_revenues <- NULL 

for (i in 1:nrow(energy_market_data_revenues)) {
  df <- energy_market_data_revenues[i,]
  df <- t(df)
  df <- as.data.frame(df)
  df <- df %>% mutate(cik = df[1,1])
  df <- df[-1,]
  df$year <- rownames(df)
  energy_all_data_revenues <- rbind(energy_all_data_revenues, df)
}

names(energy_all_data_revenues)[1] <- "revenues"

energy_regression_df <- merge(energy_all_data_revenues, energy_all_data_capex, by = c("cik", "year"))
energy_regression_df <- energy_regression_df %>% merge(energy_all_data_prices, by = c("cik", "year"))
energy_regression_df <- energy_regression_df %>% merge(ESG_scores_energy_rf_panel, by = c("cik", "year"))
energy_regression_df <- energy_regression_df %>% mutate(industry = "energy")
```




#### Beverages sector companies #######

We further repeat the analysis on a sample of 25 beverages sector companies listed on an US exchange.

```{r Loading files for beverages companies, include = FALSE}
# load excel files with cik numbers for each industry with the companies
bev <- read_excel(here("bev_cik.xlsx"), sheet = "Sheet1", col_names = TRUE)
bev <- bev[, c(1, 4:14)] # //TO DO// is it the right column??
# keeping only the cik number
bev_cik <- bev$CIK
bev_cik<-as.data.frame(bev_cik)
# load the 10Ks from downloaded files
bev_10k <- NULL
# loop that collects all reports for all companies for each industry
# this will take some minutes!!!
for (i in bev_cik) {
  output <- readtext(here("bev_10k", i))
  bev_10k <- rbind(bev_10k, output)
}
rm(output)
# simple cleaning
bev_10k$text <- str_remove_all(bev_10k$text, "\n•")
bev_10k$text <- str_remove_all(bev_10k$text, "\n")
# define columns into cik, report type and report year
bev_10k <- separate(
  bev_10k,
  1,
  into = c("cik", "type", "year", NA),
  sep = "_",
  remove = TRUE)
# only keep year
#keep the year and not the full date
bev_10k <- separate(
  bev_10k,
  "year",
  into = c("year", NA),
  sep = "-",
  remove = TRUE)
```

```{r Creating a Corpus for beverages companies, include = FALSE}
bev_corp <- corpus(bev_10k)
bev_tokens <- bev_corp %>%
  tokens(remove_punct = TRUE, # remove punctuation
         remove_numbers = TRUE, # remove numbers
         remove_symbols = TRUE,
         remove_url = TRUE) %>% # remove symbols
  tokens_tolower() # everything to lower cases
# takes some minutes!
words_to_be_removed <- c(stopwords("english"), "million", "fiscal", "january", "february",
           "march", "april", "may", "june", "july", "august", "september",
           "october", "november", "december", "business", "net", "s")
# //KEEP IN MIND// to update the list in the appendix of removed words
bev_tokens <- bev_tokens %>%
  tokens_remove(words_to_be_removed)
# apply Flesch readability measure (takes a few minutes)
bev_rd_flesch <- bev_corp %>%
  textstat_readability(measure = "Flesch", remove_hyphens = TRUE)
# apply FOG readability measure (takes a few minutes)
bev_rd_fog <- bev_corp %>%
  textstat_readability(measure = "FOG", remove_hyphens = TRUE)
```

The average Flesch readability score for the beverages companies is at around `r round(mean(bev_rd_flesch$Flesch), digits = 2)`, indicating a very complex and difficult to read text source. //TO DO// Check outliers with very negative Flesch score!

```{r Plot readability Flesch for beverages, echo=FALSE}
# all companies, all years

plot_flesch_bev <- ggplotly(ggplot(bev_rd_flesch, aes(x=bev_10k$year, y =Flesch, colour=bev_10k$cik)) + geom_point() +  ggtitle("Flesch - Readability for beverage companies"), tooltip = c("colour", "y", "x") )

x <- list(
    title = "year")

y <- list(
    title = "Readability score")

plot_flesch_bev %>% layout(xaxis = x, yaxis = y)

```

The average FOG score for our sample of 25 beverage companies from the US is `r round(mean(bev_rd_fog$FOG), digits = 2)`.

```{r Readability plots FOG for beverages, echo = FALSE, fig.width = 10 , fig.fullwidth=TRUE}
# all companies, all years
plot_bev_fog <- ggplotly(ggplot(bev_rd_fog, aes(x=bev_10k$year, y =FOG, colour=bev_10k$cik)) + geom_point() +  ggtitle("FOG - Readability for beverage companies"), tooltip = c("colour", "y", "x") )

x <- list(
    title = "year")

y <- list(
    title = "Readability score")

plot_bev_fog %>% layout(xaxis = x, yaxis = y)
```

```{r Correspondance analysis 2004 and 2020 beverages, include = FALSE}
# analysis only on one year across companies to have only max 27 data points (otherwise way too much)
# filter out the years 2004 and 2020 to show difference in correspondance
bev_2004 <- bev_10k %>%
  filter(year == 2004)
bev_2020 <- bev_10k %>%
  filter(year == 2020)
## create corpus
bev_04_corp <- corpus(bev_2004)
bev_20_corp <- corpus(bev_2020)
## Tokenization
bev_04_tokens <- bev_04_corp %>%
  tokens(remove_punct = TRUE, # remove punctuation
         remove_numbers = TRUE, # remove numbers
         remove_symbols = TRUE) %>% # remove symbols
  tokens_tolower() # everything to lower cases
bev_04_tokens <- bev_04_tokens %>%
  tokens_remove(stopwords("english"))
bev_20_tokens <- bev_20_corp %>%
  tokens(remove_punct = TRUE, # remove punctuation
         remove_numbers = TRUE, # remove numbers
         remove_symbols = TRUE) %>% # remove symbols
  tokens_tolower() # everything to lower cases
bev_20_tokens <- bev_20_tokens %>%
  tokens_remove(stopwords("english"))
## DFM
bev_04_dfm <- dfm(bev_04_tokens)
bev_20_dfm <- dfm(bev_20_tokens)
## 1D correspondence analysis
bev_04_ca <- textmodel_ca(bev_04_dfm)
bev_20_ca <- textmodel_ca(bev_20_dfm)
## 2D correspondence analysis
bev_04_ca2 <- data.frame(dim1 = coef(bev_04_ca, doc_dim = 1)$coef_document, 
                       dim2 = coef(bev_04_ca, doc_dim = 2)$coef_document,
                       doc = bev_04_ca$rownames)
bev_20_ca2 <- data.frame(dim1 = coef(bev_20_ca, doc_dim = 1)$coef_document, 
                       dim2 = coef(bev_20_ca, doc_dim = 2)$coef_document,
                       doc = bev_20_ca$rownames)
bev_04_ca2 %>%
  ggplot(aes(x=dim1, y=dim2)) +
  geom_text(aes(label = doc)) +
  theme_classic() +
  labs(x="Dimension 1", y="Dimension 2") + ggtitle("2D Correspondance analysis 2004")
bev_20_ca2 %>%
  ggplot(aes(x=dim1, y=dim2)) +
  geom_text(aes(label = doc)) +
  theme_classic() +
  labs(x="Dimension 1", y="Dimension 2") + ggtitle("2D Correspondance analysis 2020")
```



```{r Apply CSR dict for bev, include = FALSE}
bev_CSR <- dfm(bev_tokens, dictionary = dictionary_csr) # set up a dfm with word count by category
bev_CSR <- convert(bev_CSR, to = "data.frame") # convert it to df for easy merge
bev_CSR <- cbind(bev_CSR, bev_10k[,c(1,3)]) # merge with cik and year data
count_tokens_bev <- ntoken(bev_tokens) #counts total tokens in the text
count_tokens_bev <- as.data.frame(count_tokens_bev) # convert to df for easy merge
bev_CSR <- cbind(bev_CSR, count_tokens_bev) # merge with the token count
# find the relative ESG-related words 
bev_CSR_total <- bev_CSR %>% 
        select(ENVIRONMENT, EMPLOYEE, 'HUMAN RIGHTS', 'SOCIAL AND COMMUNITY') %>% 
        rowSums(na.rm=TRUE)
  
bev_CSR <- cbind(bev_CSR, bev_CSR_total) 
rm(bev_CSR_total)
  
bev_CSR <- bev_CSR %>% mutate(relative_env = ENVIRONMENT/count_tokens_bev,
                                              relative_soc = `SOCIAL AND COMMUNITY`/count_tokens_bev,
                                              relative_empl = EMPLOYEE/count_tokens_bev,
                                              relative_humans = `HUMAN RIGHTS`/count_tokens_bev,
                                              relative_overall = bev_CSR_total/count_tokens_bev)
round(mean(bev_CSR$relative_env), digits = 4)*100
round(mean(bev_CSR$relative_soc), digits = 4)*100
round(mean(bev_CSR$relative_empl), digits = 4)*100
```

```{r Relative ESG wording CSR dict for bev, echo = FALSE}
plot_ly(bev_CSR, x = ~year, y = ~relative_env, type='scatter', mode='markers',
             text = ~paste("CIK :", cik,
                           "<br> Score :", paste0(round(100*relative_env, digits = 3), "%"), 
                           "<br> Year :", year),
             textposition = "auto",
             hoverinfo = "text") %>%
  
  add_trace(y = ~relative_humans, type='scatter', mode='markers',
             text = ~paste("CIK :", cik,
                           "<br> Score :", paste0(round(100*relative_humans, digits = 3), "%"), 
                           "<br> Year :", year),
             textposition = "auto",
             hoverinfo = "text") %>%
  
  add_trace(y = ~relative_empl, type='scatter', mode='markers',
             text = ~paste("CIK :", cik,
                           "<br> Score :", paste0(round(100*relative_empl, digits = 3), "%"), 
                           "<br> Year :", year),
             textposition = "auto",
             hoverinfo = "text") %>%
  layout(
    updatemenus = list(
      list(
        type = "buttons",
        x = -0.1,
        y = 0.8,
        label = 'Category',
        buttons = list(
          list(method = "restyle",
               args = list('visible', c(TRUE, TRUE, TRUE)),
               label = "View all"))), 
      list(type = "buttons",
        x = -0.1,
        y = 0.7,
        label = 'Category',
        buttons = list(
          list(method = "restyle",
               args = list('visible', c(TRUE, FALSE, FALSE)),
               label = "Environment"),
          list(method = "restyle",
               args = list('visible', c(FALSE, TRUE, FALSE)),
               label = "Society"),
          list(method = "restyle",
               args = list('visible', c(FALSE, FALSE, TRUE)),
               label = "Employees"))))) %>%      
      layout(title = 'ESG wording. Beverage industry. CSR dictionary',
              xaxis = list(title = 'year'),
              yaxis = list(title = 'percentage', hoverformat = '.2f'), showlegend = FALSE) 

```

```{r Wordcloud CSR dictionary for beverages, echo = FALSE}
### Select CSR dictionary tokens ###
## selecting tokens
bev_CSR_all_tokens <- tokens_select(bev_tokens, dictionary_csr)
bev_CSR_hum_tokens <- tokens_select(bev_tokens, dictionary_csr$`HUMAN RIGHTS`)
bev_CSR_emp_tokens <- tokens_select(bev_tokens, dictionary_csr$EMPLOYEE)
bev_CSR_soc_tokens <- tokens_select(bev_tokens, dictionary_csr$`SOCIAL AND COMMUNITY`)
bev_CSR_env_tokens <- tokens_select(bev_tokens, dictionary_csr$ENVIRONMENT)
## creating dfm
bev_dfm <- dfm(bev_tokens)
bev_CSR_all_dfm <- dfm(bev_CSR_all_tokens)
bev_CSR_hum_dfm <- dfm(bev_CSR_hum_tokens)
bev_CSR_emp_dfm <- dfm(bev_CSR_emp_tokens)
bev_CSR_soc_dfm <- dfm(bev_CSR_soc_tokens)
bev_CSR_env_dfm <- dfm(bev_CSR_env_tokens)
## count token
bev_count_tokens <- ntoken(bev_dfm)
# wordcloud for most used words in the CSR dictionary
textplot_wordcloud(bev_CSR_all_dfm, max_words = 100,
                   color = c("grey80", "darkgoldenrod1", "tomato"))
textplot_wordcloud(bev_CSR_env_dfm, max_words = 100, color = c("grey80", "darkgoldenrod1", "tomato"))
textplot_wordcloud(bev_CSR_emp_dfm, max_words = 100, color = c("grey80", "darkgoldenrod1", "tomato"))
textplot_wordcloud(bev_CSR_soc_dfm, max_words = 100, color = c("grey80", "darkgoldenrod1", "tomato"))
```

```{r Wordcloud BBK beverages}
bev_bbk_env_tokens <- tokens_select(bev_tokens, dictionary_BBK$Environmental$Word)
bev_bbk_soc_tokens <- tokens_select(bev_tokens, dictionary_BBK$Social$Word)
bev_bbk_gov_tokens <- tokens_select(bev_tokens, dictionary_BBK$Governance$Word)

bev_bbk_env_dfm <- dfm(bev_bbk_env_tokens)
bev_bbk_soc_dfm <- dfm(bev_bbk_soc_tokens)
bev_bbk_gov_dfm <- dfm(bev_bbk_gov_tokens)

textplot_wordcloud(bev_bbk_env_dfm, max_words = 100,color = c("grey80", "darkgoldenrod1", "tomato"))
textplot_wordcloud(bev_bbk_soc_dfm, max_words = 100,color = c("grey80", "darkgoldenrod1", "tomato"))
textplot_wordcloud(bev_bbk_gov_dfm, max_words = 100,color = c("grey80", "darkgoldenrod1", "tomato"))
```

```{r Preparation relative ESG wording BBK dict for bev, inlcude = FALSE}
bev_BBK <- dfm(bev_tokens, dictionary = dictionary_BBK, valuetype = "glob") # set up a dfm with word count by category
bev_BBK <- convert(bev_BBK, to = "data.frame") # convert it to df for easy merge
bev_BBK <- cbind(bev_BBK, bev_10k[,c(1,3)]) # merge with cik and year data
bev_BBK <- cbind(bev_BBK, count_tokens_bev) # merge with the token count
# bev_BBK$year <- as.Date(bev_BBK$year, format="%d/%m/%Y") 
# find the relative ESG-related words 
total_ESG_only_BBK <- bev_BBK %>% 
  select(Governance.Word, Environmental.Word, Social.Word) %>% 
  rowSums(na.rm=TRUE)
bev_BBK <- cbind(bev_BBK, total_ESG_only_BBK) 
bev_BBK <- bev_BBK %>% mutate(relative_govern = Governance.Word/count_tokens_bev,
                                      relative_env = Environmental.Word/count_tokens_bev,
                                      relative_soc = Social.Word/count_tokens_bev,
                                      relative_overall = total_ESG_only_BBK/count_tokens_bev)
round(mean(bev_BBK$relative_env), digits = 4)*100
round(mean(bev_BBK$relative_soc), digits = 4)*100
round(mean(bev_BBK$relative_govern), digits = 4)*100
```

```{r Relative ESG wording BBK dict for bev, include = TRUE}

plot_ly(bev_BBK, x = ~year, y = ~relative_env, type='scatter', mode='markers',
             text = ~paste("CIK :", cik,
                           "<br> Score :", paste0(round(100*relative_env, digits = 3), "%"), 
                           "<br> Year :", year,
                           "<br> Type :", "Environment"),
             textposition = "auto",
             hoverinfo = "text") %>%
  
  add_trace(y = ~relative_soc, type='scatter', mode='markers',
             text = ~paste("CIK :", cik,
                           "<br> Score :", paste0(round(100*relative_soc, digits = 3), "%"), 
                           "<br> Year :", year,
                           "<br> Type :", "Society"),
             textposition = "auto",
             hoverinfo = "text") %>%
  
  add_trace(y = ~relative_govern, type='scatter', mode='markers',
             text = ~paste("CIK :", cik,
                           "<br> Score :", paste0(round(100*relative_govern, digits = 3), "%"), 
                           "<br> Year :", year,
                           "<br> Type :", "Governance"),
             textposition = "auto",
             hoverinfo = "text") %>%
  layout(
    updatemenus = list(
      list(
        type = "buttons",
        x = -0.1,
        y = 0.8,
        label = 'Category',
        buttons = list(
          list(method = "restyle",
               args = list('visible', c(TRUE, TRUE, TRUE)),
               label = "View all"))), 
      list(type = "buttons",
        x = -0.1,
        y = 0.7,
        label = 'Category',
        buttons = list(
          list(method = "restyle",
               args = list('visible', c(TRUE, FALSE, FALSE)),
               label = "Environment"),
          list(method = "restyle",
               args = list('visible', c(FALSE, TRUE, FALSE)),
               label = "Society"),
          list(method = "restyle",
               args = list('visible', c(FALSE, FALSE, TRUE)),
               label = "Governance"))))) %>%      
      layout(title = 'ESG wording. Beverage industry. BBK dictionary',
              xaxis = list(title = 'year'),
              yaxis = list(title = 'percentage', hoverformat = '.2%'), showlegend = FALSE) 
```

``` {r Read file with ESG scores Energy, include = FALSE}
ESG_scores_beverages <- read_excel(here("ESG_scores_beverages.xlsx"), sheet = "ESG", col_names = TRUE)
names(ESG_scores_beverages)[4] <- "cik" #rename the cik column for convenience
ESG_scores_beverages$cik <- as.character(ESG_scores_beverages$cik)

ESG_scores_beverages_rf <- ESG_scores_beverages[,c(4,13:30)]

for (i in 2:19) { # rename the columns as years
names(ESG_scores_beverages_rf)[i] <- paste0(2023-i)}

ESG_scores_beverages_rf_panel <- NULL 

for (i in 1:nrow(ESG_scores_beverages_rf)) {
  df <- ESG_scores_beverages_rf[i,]
  df <- t(df)
  df <- as.data.frame(df)
  df <- df %>% mutate(cik = df[1,1])
  df <- df[-1,]
  df$year <- rownames(df)
  ESG_scores_beverages_rf_panel <- rbind(ESG_scores_beverages_rf_panel, df)
}


ESG_scores_beverages_rf_panel <- merge(ESG_scores_beverages_rf_panel, bev_BBK, by = c("cik", "year"))

ESG_scores_beverages_rf_panel <- as.data.frame(ESG_scores_beverages_rf_panel)
names(ESG_scores_beverages_rf_panel)[3] <- "rating"
ESG_scores_beverages_rf_panel$rating <- as.numeric(ESG_scores_beverages_rf_panel$rating)
ESG_scores_beverages_rf_panel <- na.omit(ESG_scores_beverages_rf_panel)

```

```{r add data for market parameters beverages, include = FALSE}

beverages_market_data <- read_excel(here("revenue_figures.xlsx"), sheet = "beverages", col_names = TRUE)

names(beverages_market_data)[3] <- "cik" #rename the cik column for convenience
beverages_market_data$cik <- as.character(beverages_market_data$cik)

for (i in 10:27) { # rename the columns as years
names(beverages_market_data)[i] <- paste0(2031-i)}
beverages_market_data_capex <- beverages_market_data[c(3, 10:27)]

beverages_all_data_capex <- NULL 

for (i in 1:nrow(beverages_market_data_capex)) {
  df <- beverages_market_data_capex[i,]
  df <- t(df)
  df <- as.data.frame(df)
  df <- df %>% mutate(cik = df[1,1])
  df <- df[-1,]
  df$year <- rownames(df)
  beverages_all_data_capex <- rbind(beverages_all_data_capex, df)
}

names(beverages_all_data_capex)[1] <- "capex"

# repeat the same to get prices 
for (i in 28:45) { # rename the columns as years
names(beverages_market_data)[i] <- paste0(2049-i)}
beverages_market_data_prices <- beverages_market_data[c(3, 28:45)]

beverages_all_data_prices <- NULL 

for (i in 1:nrow(beverages_market_data_prices)) {
  df <- beverages_market_data_prices[i,]
  df <- t(df)
  df <- as.data.frame(df)
  df <- df %>% mutate(cik = df[1,1])
  df <- df[-1,]
  df$year <- rownames(df)
  beverages_all_data_prices <- rbind(beverages_all_data_prices, df)
}

names(beverages_all_data_prices)[1] <- "share_price"

# and revenues
for (i in 46:63) { # rename the columns as years
names(beverages_market_data)[i] <- paste0(2067-i)}
beverages_market_data_revenues <- beverages_market_data[c(3, 46:63)]

beverages_all_data_revenues <- NULL 

for (i in 1:nrow(beverages_market_data_revenues)) {
  df <- beverages_market_data_revenues[i,]
  df <- t(df)
  df <- as.data.frame(df)
  df <- df %>% mutate(cik = df[1,1])
  df <- df[-1,]
  df$year <- rownames(df)
  beverages_all_data_revenues <- rbind(beverages_all_data_revenues, df)
}

names(beverages_all_data_revenues)[1] <- "revenues"

beverages_regression_df <- merge(beverages_all_data_revenues, beverages_all_data_capex, by = c("cik", "year"))
beverages_regression_df <- beverages_regression_df %>% merge(beverages_all_data_prices, by = c("cik", "year"))
beverages_regression_df <- beverages_regression_df %>% merge(ESG_scores_beverages_rf_panel, by = c("cik", "year"))
beverages_regression_df <- beverages_regression_df %>% mutate(industry = "beverages")
```

#### Trends between industries ####


Both measures of readability used (Flesch and FOG) show a similar picture across all three industries. According to both measure the 10Ks seems to be of a very complex nature. All industries included in our analyses do obtained a score that is well under respectively over the range for text sources that are best understood by university graduates. The beverage companies do have a slight higher complexity rating, which can be attribute to the few outliers with extreme values in both measures. This again shows the similarity between those common readability measures and also indicates a disqualification for common readability measure for the context of financial reports.


```{r compare industry esg wording, echo=FALSE}
fashion_time_evol <- fashion_BBK %>% group_by(year) %>% # creates a table of mean ESG scores through time 
                                summarise(mean_env = mean(relative_env),
                                          mean_soc = mean(relative_soc), 
                                          mean_gov = mean(relative_govern),
                                          mean_total = mean(relative_overall))
energy_time_evol <- energy_BBK %>% group_by(year) %>% # creates a table of mean ESG scores through time 
                                summarise(mean_env = mean(relative_env),
                                          mean_soc = mean(relative_soc), 
                                          mean_gov = mean(relative_govern),
                                          mean_total = mean(relative_overall))
bev_time_evol <- bev_BBK %>% group_by(year) %>% # creates a table of mean ESG scores through time 
                                summarise(mean_env = mean(relative_env),
                                          mean_soc = mean(relative_soc), 
                                          mean_gov = mean(relative_govern),
                                          mean_total = mean(relative_overall))

plot_ly() %>%
    add_markers(data=energy_time_evol, name="Energy", x = ~year, y = ~mean_total) %>%
    add_markers(data=fashion_time_evol, name="Fashion", x = ~year, y = ~mean_total) %>% 
    add_markers(data=bev_time_evol, name="Beverages", x = ~year, y = ~mean_total) %>%
    add_markers(data=energy_time_evol, name="Energy", x = ~year, y = ~mean_env) %>%
    add_markers(data=fashion_time_evol, name="Fashion", x = ~year, y = ~mean_env) %>% 
    add_markers(data=bev_time_evol, name="Beverages", x = ~year, y = ~mean_env) %>%    
    add_markers(data=energy_time_evol, name="Energy", x = ~year, y = ~mean_soc) %>%
    add_markers(data=fashion_time_evol, name="Fashion", x = ~year, y = ~mean_soc) %>% 
    add_markers(data=bev_time_evol, name="Beverages", x = ~year, y = ~mean_soc) %>%
  layout(
    updatemenus = list(
      list(
        type = "buttons",
        x = -0.1,
        y = 0.8,
        label = 'Category',
        buttons = list(
          list(method = "restyle",
               args = list('visible', c(TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE)),
               label = "View all"))), 
      list(type = "buttons",
        x = -0.1,
        y = 0.7,
        label = 'Category',
        buttons = list(
          list(method = "restyle",
               args = list('visible', c(TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)),
               label = "Overall ESG wording"),
          list(method = "restyle",
               args = list('visible', c(FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, FALSE, FALSE, FALSE)),
               label = "Environment wording"),
          list(method = "restyle",
               args = list('visible', c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE)),
               label = "Society wording"))))) %>%      
      layout(title = 'ESG wording. Comparison between industries',
              xaxis = list(title = 'year'),
              yaxis = list(title = 'wording percentage', hoverformat = '.2%'), showlegend = FALSE) 

```

### Analysing the parameters that affect ESG scores ###

```{r regressions, include = TRUE}
beverages_regression_df <- beverages_regression_df[c(1:6,13:17)]
energy_regression_df <- energy_regression_df[c(1:6,13:17)]
fashion_regression_df <- fashion_regression_df[c(1:6,13:17)]

all_data_for_regr <- rbind(beverages_regression_df, energy_regression_df)
all_data_for_regr <- rbind(all_data_for_regr, fashion_regression_df)
all_data_for_regr <- na.omit(all_data_for_regr)
all_data_for_regr[3:10] <- data.frame(lapply(all_data_for_regr[3:10], function(x) as.numeric(as.character(x))))
all_data_for_regr <- all_data_for_regr[order(all_data_for_regr$year),]  %>%
                      group_by(cik) %>% 
                      mutate(price_growth = growth.rate(start = end(share_price) + 1, lag = 1))

growth_rate <- function(x) {(x/lag(x)-1) * 100 }

all_data_for_regr <- all_data_for_regr[order(all_data_for_regr$cik, all_data_for_regr$year),]  %>% 
                      group_by(cik) %>% 
                      mutate(price_growth = growth_rate(share_price))

corr_matrix <- cor(all_data_for_regr[3:10])
corrplot(corr_matrix, method = "circle")
```
#### Regression results ####
We have additionally tested our hypothesis via an OLS with the following parameters: 

ESG_Score ~ alpha + beta x ESG_wording + Beta_2 x controls + error

The control variables include industry (beverages, energy or fashion), year, firm adjusted (for splits and dividends) share price growth rate, CAPEX and revenue. As discussed above, we beleive that there should be differences in ESG wording as well as ESG scores between industries. Moreover, larger and more profitable companies are expected to have more resources to invest in ESG activities, which would result in a higher rating as well. Controlling for time will allow us to account for the trend of increased ESG scores and ratings, which we have seen on the graphs above. 

Our model is specified as follows: we control for industry and time effects in all regressions. 
Specification 1: all three types of ESG scores are used, industry and time controls are used. 


Specification 5: all three types of ESG scores are used, firm and time controls are used. 

The results of the regression analysis are presented below:
```{r regression results, results ='asis', message = FALSE}
# most basic model with industry and year FE
model_1 <- lm(rating ~ relative_overall + relative_env + relative_govern + 
                revenues + capex + price_growth + as.factor(year) + as.factor(industry), 
                data = all_data_for_regr)
summary(model_1)

# with interaction term for industry * wording
model_2 <- lm(rating ~ relative_env*as.factor(industry) +
                revenues + capex + price_growth + as.factor(year) + as.factor(industry), 
                data = all_data_for_regr)
summary(model_2)

# to prove that for social wording the interaction term does not matter
model_2_supplement <- lm(rating ~ relative_soc*as.factor(industry) +
                revenues + capex + price_growth + as.factor(year) + as.factor(industry), 
                data = all_data_for_regr)

# a model with firm fixed effects
model_3 <- lm(rating ~ relative_overall + relative_env + relative_govern + 
                revenues + capex + share_price + as.factor(year) + as.factor(cik), 
                data = all_data_for_regr)
summary(model_3)



stargazer(model_1, model_2, model_3, title="OLS results", align=TRUE, type = "html")
```

Overall, the models above suggest that ESG ratings are explained by CAPEX, time effect, industry and the ESG wording. We note that the 

The results of model 2 are particularly interesting, since we note that the interaction between environment-related wording with industry has a statistically significant effect on ESG scores. Having tested the same model specification with social and governance wording, we did not find a similar effect. Thus, we can conclude that for energy and fashion sectors ESG wording is of particular importance. 

The most notable, though slightly disappointing, result is that of Model 5, since it shows that the variation in ESG scores is explained by the firm-specific characteristics, and the only significant covariate that we obtain in the end is CAPEX. 

#### Machine learning. Regression tree ####
Since we expect an obvious non-linearity in the effect of the covairiates on the ESG scores, we decided to add a regression tree analysis to the model. The tree was pre-pruned to have a maximum depth of 5 and the minimum number of observations of 20 per bucket to reduce overfitting. 

The results of the analysis are presented below: 

```{r ML <3, warning=FALSE}
## cut the unneeded data for ML 
all_data_for_regr_ML <- all_data_for_regr[c(2:11, 14)]


set.seed(2021)

ML_model <- rpart(
  formula = rating ~ .,
  data    = all_data_for_regr_ML,
  method  = "anova", 
  control = rpart.control(minsplit = 2, cp = 0, maxdepth = 5, minbucket = 20)
  )

rpart.plot(ML_model)
```
Similarly to regular OLS, we note that the tree's first split is set at a certain level of CAPEX, which contributes to our understanding that companies that are large and actively investing will have higher ratings. Additionally, we note that industry effect, time and ESG wording play important roles in the analysis. 

Thus, we conclude that the ESG 10-k wording effect on company's ESG rating exists. However, it is definitely not the most important feature that drives company's ESG ratings. 

```{r}
vip(ML_model, num_features = 10) + ggtitle("Feature importance in ML") + theme_bw()
```


#### Limitations ####

Data collection: The SEC has limited the access for automated tools that download EDGAR filings (e.g. 10-K reports). Therefore, most companies had incomplete data that had to be added manually. That makes it much more difficult if you want so scale the scope of the research question.

There are a variety of different ESG-Ratings on the market. The growing usage of these ESG scores has raised questions by policymakers, investors, researchers, and firms about their reliability, consistency, and overall quality. It is not clear, how exactly the scores are rated. Researchers have furthermore documented, that some ESG rating providers retrocactively rewrite scores (Berg, Fabisik, Sautner, 2020, p.1). 

References: 
Berg, Florian and Fabisik, Kornelia and Sautner, Zacharias, Rewriting History II: The (Un)Predictable Past of ESG Ratings (November 3, 2020). European Corporate Governance Institute – Finance Working Paper 708/2020

#### Further actions ####
We further plan to expand the analysis by:
1) Adding more observations from other sectors. Since between-industry comparison shows differences in attention to ESG between different business sectors, it will be interesting to identify those sectors that are concerned about ESG the most. 
2) Analyzing not only industry, but also firm size effect, on company's ESG rating. It seems reasonable that larger companies will face more pressure from the regulators and clients and will have enough cash flows to make more ESG-friendly decisions. 
3) We will additionally expand the analysis of the relationship between esg ratings and words and assess environmental, governance and social wording separately.

#### Appendix ####
Appendix 1: Readability analysis with FOG measures for all three industry samples		Appendix 1: Words that have been additionaly removed during the tokenization process due to insignificance.

Appendix 2: Comparison of correspondence Analysis 2020 across all three industry samples

Appendix 3: CSR key tokens per dictionary dimension		

Appendix 4: BBK key tokens per dictionary dimension		

Appendix X: Words that have been additionally removed during the tokenization process due to insignificance.

words_to_be_removed <- c(stopwords("english"), "million", "fiscal", "january", "february",
           "march", "april", "may", "june", "july", "august", "september",
           "october", "november", "december", "business", "net", "s")
           

Appendix XX: Barplot of 75 most frequent dictionary tokens for the CSR dictionary
```{r Preparing for barplot of 75 most frequent dictionary tokens for the CSR dictionary, include=FALSE}
fashion_csr_all_top75_dfm <- textstat_frequency(fashion_csr_all_dfm, n = 75)
fashion_csr_all_top75_dfm <- fashion_csr_all_top75_dfm %>%
  mutate(feature = forcats::fct_reorder(feature, desc(frequency)))
```


```{r Barplot of 75 most frequent dictionary tokens for the CSR dictionary, echo = FALSE}
ggplotly(ggplotly(ggplot(fashion_csr_all_top75_dfm, aes(x = feature, y = frequency))
         + geom_point(color="steelblue") +
           theme(axis.text.x = element_text(angle = 90, hjust = 1))))
```
